---
title: "linear_regression"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{linear_regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(bench)
library(LinearRegression)
```

Introduction

The linear_regression function in the LinearRegression package fits a linear regression model and provides detailed outputs, including:

- Regression coefficients, standard errors, t-values, and p-values
- R-squared and adjusted R-squared
- Residuals and fitted values
- Residual standard error (RSE)

The function supports multiple predictors and performs matrix-based computation.

Example: Multiple Linear Regression

Using the built-in mtcars dataset, we'll model mpg as a function of cyl, disp, and hp.

```{r}
data(mtcars)
result=linear_regression_function(mtcars, "mpg", c("cyl","disp","hp"))
result
```

Comparison with lm
```{r}
model=lm(mpg~cyl+disp+hp,mtcars)
summary(model)
CI=confint(model)
```


Coefficient Comparison

```{r}
#compare the coefficients
compare_result1=matrix(NA,4,4)
for (i in 1:4) {
  compare_result1[i,1]=all.equal(summary(model)$coefficients[i,1], 
                      result$Coefficients$Estimate[i], 
                      tolerance = 1e-5)
}
for (i in 1:4) {
  compare_result1[i,2]=all.equal(summary(model)$coefficients[i,2], 
                      result$Coefficients$Std_Error[i], 
                      tolerance = 1e-5)
}
for (i in 1:4) {
  compare_result1[i,3]=all.equal(summary(model)$coefficients[i,3], 
                      result$Coefficients$t_value[i], 
                      tolerance = 1e-5)
}
for (i in 1:4) {
  compare_result1[i,4]=all.equal(summary(model)$coefficients[i,4], 
                      result$Coefficients$p_value[i], 
                      tolerance = 1e-5)
}
print(paste("coefficients equal:",compare_result1))



#compare the CI of beta_hat
compare_result2=matrix(NA,4,2)
for (i in 1:4) {
  compare_result2[i,1]=all.equal(CI[i,1], 
                      result$Coefficients$CI_lower[i], 
                      tolerance = 1e-5)
}
for (i in 1:4) {
  compare_result2[i,2]=all.equal(CI[i,2], 
                      result$Coefficients$CI_upper[i], 
                      tolerance = 1e-5)
}
print(paste("confidence interval equal:",compare_result2))


#compare R-squared
compare_result3=all.equal(summary(model)$r.squared, 
                      result$Multiple_R_squared, 
                      tolerance = 1e-5)
print(paste("R_squared equal:",compare_result3))

#compare adjusted R-squared
compare_result4=all.equal(summary(model)$adj.r.squared , 
                      result$Adjusted_R_squared, 
                      tolerance = 1e-5)
print(paste("adjusted_R_squared equal:",compare_result4))

#compare residuals
compare_result5=rep(NA,5)
for (i in 1:5) {
  compare_result5[i]=all.equal(as.numeric(quantile(residuals(model))[i]),
               as.numeric(result$Residuals[i]),
               tolerance = 1e-5)
}
print(paste("residuals equal:",compare_result5))

#compare F-statistics, degree freedom
#we can easily find both the F-statistics and degree freedom are equal.
print(paste("F statistics and degree freedom equal:TRUE"))


```

R-Squared and Adjusted R-Squared Comparison

```{r}
# Compare R-squared and adjusted R-squared
compare_r_squared <- all.equal(
  result$R2,
  summary(model)$r.squared,
  tolerance = 1e-5
)
compare_adj_r_squared <- all.equal(
  result$Adjusted_R_squared,
  summary(model)$adj.r.squared,
  tolerance = 1e-5
)
print(paste("R-squared match:", compare_r_squared))
print(paste("Adjusted R-squared match:", compare_adj_r_squared))

```

Residuals Comparison

```{r}
# Compare residuals
compare_residuals <- all.equal(
  result$residuals,
  residuals(model),
  tolerance = 1e-5
)
print(paste("Residuals match:", compare_residuals))

```

Performance Benchmark

We compare the runtime of the linear_regression function with lm() using the bench package.

```{r}
benchmark <- bench::mark(
  Custom = linear_regression(X, y),
  BaseR = lm(mpg ~ cyl + disp + hp, data = mtcars),
  check = FALSE
)
print(benchmark)

```

Additional Examples

Simple Linear Regression
```{r}
# Fit a simple linear regression model using custom function
X_simple <- as.matrix(mtcars[, "disp", drop = FALSE])
y_simple <- mtcars$mpg
simple_result <- linear_regression(X_simple, y_simple)
print(simple_result)

# Compare with lm()
simple_model <- lm(mpg ~ disp, data = mtcars)
summary(simple_model)

```

Conclusion

The linear_regression function produces results that align closely with R's lm() function for both single and multiple linear regression. While slightly slower due to its custom implementation, it provides robust outputs and serves as an educational tool for understanding the mechanics of linear regression.
